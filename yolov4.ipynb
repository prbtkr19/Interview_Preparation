{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color =\"orange\"> Backbone Part </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in yolov4 CSPDarkent-53 used as backbone\n",
    "- it uses Dense Block and CSP Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense NEt  is composed of number of dense block and each dense block is interconnected with feature blocl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense block is combination of multiple cnn blocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSPNET : cross stage partial network\n",
    "-   split input channel into two parts and send one only channel to computation block and remaining concatenate at the end.\n",
    "-   only half information se sent to computation block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darknet-53 used in yolov3\n",
    "and activation function used in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in yolov4 they use CSP Darkent 53 instead of darknet 53\n",
    "the activation function they used is mish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\"> Neck </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPP (Spatial Pyramid Pooling): Enhances the receptive field by pooling features at different scales, improving the model's ability to detect objects at various sizes.\n",
    "PANet (Path Aggregation Network): Facilitates better information flow from the backbone to the head of the network, aiding in robust multi-scale feature fusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neck is called feature aggregator\n",
    "usully feature map comes from backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why dowe need neck?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FPN : feature pyramid network : it combines high level feature map to low level feature map to get good results\n",
    "but yolov4 doesnot used FPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   YOLOv4 is a one-stage object detection model that builds off of the original YOLO models. \n",
    "-   Modern object detectors are usually composed of two components, a backbone and a head. \n",
    "-   The backbone is typically pre-trained on larger image classification dataset, usually ImageNet, and serves to encode relevant information about the input.\n",
    "-    The head predicts object classes and bounding box information. This paper also identifies a “neck”, which they define as layers between the backbone and head that serve to collect feature maps from different stages of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   The paper also collects training methods that it categories into “bag-of-freebies”(BoF) and “bag-of-specials”(BoS).\n",
    "\n",
    "-    BoF are training methods that have either only have an impact on training strategy or the training cost.\n",
    "-    BoS are training strategies that increase inference cost by a small amount but also provide potential increases in model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper Contributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What methods did the paper propose to address the problem?\n",
    "The paper proposed various data augmentation strategies to improve the efficacy of the model training process without increasing the model’s demands on computing power and RAM. The most successful methods mentioned by the authors were Mosaic Image clipping, Self-Adversarial Training (SAT) , and Cross mini-batch Normalization (CmBN). Mosaic Image clipping formed each individual sample by composing four individual images together. SAT was a unique training regimen that had the model first attempt to remove the object in question and perform object detection on the edited image. CmBN allowed data scientists to assess statistics across multiple mini-batches, providing a better overview on the performance of the mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are the paper’s contributions different from previous related works?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper expands on multiple prior works utilizing work within the field of Neural Networks and within Computer Vision to improve the overall performance of the detection module. The paper in itself does not propose a grand new architecture, but rather focuses on utilizing the findings within the field to power their model and allow it to a more democratized model. In particular, it runs twice as fast as EfficientNet with comparable performance, and it improves YOLOv3’s AP and FPS by 10% and 12% respectively. This was all done on a single GPU, which is much more accessible to individuals, giving the power to train a real time detection system to (almost) everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper Limitations, Further Research, and/or Potential Applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the biggest applications/contributions that this paper makes is that it helps improve the feasibility/practicality of using the YOLO models for object detection. By developing YOLOv4 such that it could be trained and tested on only one GPU, it reduces the amount of computational resources needed to use this model.\n",
    "\n",
    "While the proposed framework produces state of the art results at high speeds, they were only trained on a single GPU. The results from these experiments are quite promising, but in practice there are few instances where one is limited to a single GPU during the training step, rather than just inference. This then begs the question as to what results could be achieved when training with multiple GPUs, and this could also lead to a potential application: upscaling the framework for industry standard model training.\n",
    "\n",
    "Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Specials:\n",
    "\n",
    "Techniques that enhance inference efficiency with minimal computational cost, including:\n",
    "Mish Activation Function: Used in the backbone to provide smoother gradients and better feature learning.\n",
    "CIoU (Complete Intersection over Union) Loss: Improves the bounding box regression by considering aspect ratio and object center alignment.\n",
    "DropBlock Regularization: Improves generalization by randomly dropping contiguous regions in feature maps during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Freebies:\n",
    "\n",
    "Techniques that improve training without affecting inference cost, such as:\n",
    "Mosaic Data Augmentation: Allows the model to see multiple contexts for an object by stitching together four training images.\n",
    "Self-Adversarial Training (SAT): The model generates adversarial examples during training to enhance robustness against perturbations.\n",
    "Class Label Smoothing: Reduces overfitting by smoothing the target labels during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yolov8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
