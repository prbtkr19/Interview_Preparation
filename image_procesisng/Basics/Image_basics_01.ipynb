{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color =\"Red\"> Digital Image Processing </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Digital image processing is the use of algorithms and mathematical models to process and analyze digital images. \n",
    "\n",
    "-   The goal of digital image processing is to enhance the quality of images, extract meaningful information from images, and automate image-based tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color =\"orange\"> steps involved in digital image processing</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Image acquisition: This involves capturing an image using a digital camera or scanner, or importing an existing image into a computer.\n",
    "\n",
    "- Image enhancement: This involves improving the visual quality of an image, such as increasing contrast, reducing noise, and removing artifacts.\n",
    "\n",
    "- Image restoration: This involves removing degradation from an image, such as blurring, noise, and distortion.\n",
    "\n",
    "- Image segmentation: This involves dividing an image into regions or segments, each of which corresponds to a specific object or feature in the image.\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digital image processing is widely used in a variety of applications, including medical imaging, remote sensing, computer vision, and multimedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color =\"orange\"> Image processing mainly include the following steps:</font></center>\n",
    "\n",
    "- Importing the image via image acquisition tools; \n",
    "- Analysing and manipulating the image; \n",
    "- Output in which result can be altered image or a report which is based on analysing that image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color =\"orange\"> Image:</font>\n",
    "-   An image is defined as a two-dimensional function,F(x,y), where x and y are spatial coordinates, and the amplitude of F at any pair of coordinates (x,y) is called the intensity of that image at that point. When x,y, and amplitude values of F are finite, we call it a digital image.\n",
    "\n",
    "-   In other words, an image can be defined by a two-dimensional array specifically arranged in rows and columns. \n",
    "\n",
    "- Digital Image is composed of a finite number of elements, each of which elements have a particular value at a particular location.These elements are referred to as picture elements,image elements,and pixels.\n",
    "-   A Pixel is most widely used to denote the elements of a Digital Image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color =\"orange\">Types of Images</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.<b>BINARY IMAGE</b> : ['Monochrome']\n",
    "-     The binary image as its name suggests, contain only two pixel elements i.e 0 & 1,where 0 refers to black and 1 refers to white. This image is also known as Monochrome.\n",
    "\n",
    "2.<b>BLACK AND WHITE IMAGE </b>: \n",
    "-       The image which consist of only black and white color is called BLACK AND WHITE IMAGE.\n",
    "\n",
    "3.<b>8 bit COLOR FORMAT</b> :['Grayscale']\n",
    "-        It is the most famous image format.\n",
    "-       It has 256 different shades of colors in it and commonly known as Grayscale Image.\n",
    "-        In this format, 0 stands for Black, and 255 stands for white, and 127 stands for gray.\n",
    "\n",
    "4.<b>16 bit COLOR FORMAT</b>: ['High Color Format']\n",
    "-       It is a color image format. \n",
    "-       It has 65,536 different colors in it.It is also known as High Color Format. \n",
    "-       In this format the distribution of color is not as same as Grayscale image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">A 16 bit format is actually divided into three further formats which are Red, Green and Blue. That famous RGB format.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Pixel</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   A pixel is the smallest unit of a digital image.\n",
    "-   Each pixel has certain distinctive features; for instance, its location within the image which is defined by coordinates (usually measured in terms of rows and columns) as well as color details, brightness degree, etc., and sometimes — transparency value.\n",
    "- An image resolution is based on the number of pixels it incorporates, and higher resolutions generally lead to more detailed images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=\"orange\"> Defining Key Terminologies </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pixel (Picture Element):\n",
    "-    A pixel is the smallest part of a computer picture. \n",
    "-   It shows one spot in the whole photo. Every little square has information about color, brightness   and position. \n",
    "-   When these squares are put together with others they make a complete picture that we can see. Pixels are the parts that make up digital screens. They arrange together to show letters, pictures and videos.\n",
    "\n",
    "Resolution :\n",
    "\n",
    "-   Resolution means the number of little squares, called pixels, in a digital photo.\n",
    "-    It’s usually measured by width and height size. Usual measurements for resolution are pixels per inch (PPI) for pictures that get printed and pixels per centimeter (PPCM). \n",
    "-   For example, a screen that can show pictures at 1920 x 1080 has more tiny dots or pixels from left to right and has 1920 pixels horizontally and 1080 pixels vertically.\n",
    "\n",
    "Pixel Density: \n",
    "\n",
    "-   Display resolution is the number of tiny dots on a screen, often shown as pixels per inch (PPI) for screens.\n",
    "-    It decides how clear a picture looks, and more pixels make it sharper. \n",
    "-   Mobile phones with good picture quality often have lots of tiny dots on the screen, making images colorful and clear.\n",
    "\n",
    "Color Depth:\n",
    "\n",
    "-   Bit depth, also called color depth, means how many bits show the color of each pixel. \n",
    "-   Usual values are 8-bit, 16-bit and 24-bit color levels. \n",
    "-   The more bits a pixel has, the more colors it can show. This makes for a wider and deeper range of colors.\n",
    "\n",
    "Raster and Vector Graphics: \n",
    "\n",
    "-   Raster graphics, a type of image creation, pixels are very important. \n",
    "-   These pictures are made using lots of tiny squares called pixels. \n",
    "-   In contrast, vector drawings use math equations to make shapes. \n",
    "-   This lets them get bigger without losing picture quality.\n",
    "-    Vector graphics can’t use pixels, so they are good for jobs like making logos and drawing pictures.\n",
    "\n",
    "Aspect Ratio:\n",
    "-    Aspect ratio means the balance between an image’s width and height. \n",
    "-   Common aspect ratios include 4:3, 16:9, and 1:1.\n",
    "-    Different devices and mediums can have special size rules, affecting how pictures are shown or taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\"> Why do pixelated images lose detail? </fomt>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Low resolution leads to pixelation, where the individual pixels of an image become visible. Each pixel stands for a bigger space and hence the fine details are lost. Smaller pixels, there are finer details preserved in higher resolution images and the image created appears more realistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\"> What is the impact of pixel density on display quality? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display clarity is directly influenced by pixel density. Increased pixel density means more vivid visuals thus the visibility of individual pixels is reduced, and this enhances its entire image quality. This is evident in high-resolution screen devices such as smartphones and tablets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\"> PHASES OF IMAGE PROCESSING </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-   1.ACQUISITION– It could be as simple as being given an image which is in digital form. The main work involves: \n",
    "-   a) Scaling \n",
    "-   b) Color conversion(RGB to Gray or vice-versa) \n",
    "\n",
    "-   2.IMAGE ENHANCEMENT– It is amongst the simplest and most appealing in areas of Image Processing it is also used to extract some hidden details from an image and is subjective.\n",
    "\n",
    "-   3.IMAGE RESTORATION– It also deals with appealing of an image but it is objective(Restoration is based on mathematical or probabilistic model or image degradation).\n",
    "\n",
    "-   4.COLOR IMAGE PROCESSING– It deals with pseudocolor and full color image processing color models are applicable to digital image processing. \n",
    "\n",
    "-   5.WAVELETS AND MULTI-RESOLUTION PROCESSING– It is foundation of representing images in various degrees. \n",
    "\n",
    "-   6.IMAGE COMPRESSION-It involves in developing some functions to perform this operation. It mainly deals with image size or resolution. \n",
    "\n",
    "-   7.MORPHOLOGICAL PROCESSING-It deals with tools for extracting image components that are useful in the representation & description of shape. \n",
    "\n",
    "-   8.SEGMENTATION PROCEDURE-It includes partitioning an image into its constituent parts or objects. Autonomous segmentation is the most difficult task in Image Processing.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color =\"orange\">Advantages of Digital Image Processing:</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-   Improved image quality: \n",
    "\n",
    "-   Increased efficiency: Digital image processing algorithms can process images much faster than humans, making it possible to analyze large amounts of data in a short amount of time.\n",
    "\n",
    "-   Increased accuracy: Digital image processing algorithms can provide more accurate results than humans, especially for tasks that require precise measurements or quantitative analysis.\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color =\"orange\">Disadvantages of Digital Image Processing:</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-   High computational cost: Some digital image processing algorithms are computationally intensive and require significant computational resources.\n",
    "\n",
    "-   Limited interpretability: Some digital image processing algorithms may produce results that are difficult for humans to interpret, especially for complex or sophisticated algorithms.\n",
    "\n",
    "-   Dependence on quality of input: The quality of the output of digital image processing algorithms is highly dependent on the quality of the input images. Poor quality input images can result in poor quality output.\n",
    "\n",
    "-   Limitations of algorithms: Digital image processing algorithms have limitations, such as the difficulty of recognizing objects in cluttered or poorly lit scenes, or the inability to recognize objects with significant deformations or occlusions.\n",
    "\n",
    "-   Dependence on good training data: The performance of many digital image processing algorithms is dependent on the quality of the training data used to develop the algorithms. Poor quality training data can result in poor performance of the algorit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\"> Difference between Dilation and Erosion </font>\n",
    "-   Dilation and Erosion are basic morphological processing operations that produce contrasting results when applied to either gray-scale or binary images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dilation: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-   Dilation is the reverse process with regions growing out from their boundaries.\n",
    "-   Dilation is A XOR B.\n",
    "-   It increases the size of the objects\n",
    "-   It fills the holes and broken areas\n",
    "-   It increases the brightness of the objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erosion: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Erosion involves the removal of pixels ate the edges of the region.\n",
    "-   Erosion is just the dual of Dilation.\n",
    "-   It decreases the size of the objects.\n",
    "-   It removes the small anomalies.\n",
    "-   It reduces the brightness of the bright objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both dilation and erosion are produced by the interaction of s set called a structuring element(SE). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Difference Between RGB, CMYK, HSV, and YIQ Color Models </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Different types of colour models are used in multiple fields like in hardware, in multiple applications of creating animation, etc.  \n",
    "\n",
    "Let’s see each colour model and its application.\n",
    "\n",
    "-   RGB\n",
    "-   CMYK\n",
    "-   HSV \n",
    "-   YIQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>RGB</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   The RGB colour model is the most common colour model used in Digital image processing and openCV. -   The colour image consists of 3 channels.\n",
    "-    One channel each for one colour. \n",
    "-   Red, Green and Blue are the main colour components of this model.\n",
    "-    All other colours are produced by the proportional ratio of these three colours only. 0 represents the black and as the value increases the colour intensity increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>CMYK</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   CMYK colour model is widely used in printers.\n",
    "-    It stands for Cyan, Magenta, Yellow and Black (key). \n",
    "-   It is a subtractive colour model.\n",
    "-    0 represents the primary colour and 1 represents the lightest colour.\n",
    "-    In this model, point (1, 1, 1) represents black, and (0,0,0) represents white.\n",
    "-    It is a subtractive model thus the value is subtracted from 1 to vary from least intense to a most intense colour value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>HSV</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   The image consists of three channels. Hue, Saturation and Value are three channels.\n",
    "-   This colour model does not use primary colours directly.\n",
    "-    It uses colour in the way humans perceive them. \n",
    "-   Hue is a colour component. Since the cone represents the HSV model, the hue represents different colours in different angle ranges. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Saturation as the name suggest describes the percentage of the colour.\n",
    "-   Sometimes this value lies in the 0 to 1 range.\n",
    "-    0 being the grey and 1 being the primary colour. \n",
    "-   Saturation describes the grey colour.\n",
    "-   The value represents the intensity of the colour chosen.\n",
    "-    Its value lies in percentage from 0 to 100. 0 is black and 100 is the brightest and reveals the colour. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   HSV model is used in histogram equalization and converting grayscale images to RGB colour images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YIQ: \n",
    "-   YIQ is the most widely colour model used in Television broadcasting.\n",
    "-    Y stands for luminance part and IQ stands for chrominance part.\n",
    "-    In the black and white television, only the luminance part (Y) was broadcast. \n",
    "-   The y value is similar to the grayscale part.\n",
    "-    The colour information is represented by the IQ part.\n",
    "-   YIQ model is used in the conversion of grayscale images to RGB colour images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">wHY PIXEL values are between 0-255 only </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Most of the screens use 24 bits RGB pixels, each pixel has three components in order of** Red, Green, Blue**\n",
    "-    leaving 8 bits for each color component.\n",
    "-   The minimum and maximum decimal number that can be represented through 8 bits is 0 and 255.\n",
    "- A pixel is assigned a full byte = 8 bits. Once you assign eight bits to a pixel, you want as finely distinguished intensity levels as you can get, which is 256 levels (0–255, because 8 bits in binary can represent this range in decimal 00000000–11111111)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
